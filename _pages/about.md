---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a third-year undergraduate student at <a href='https://zhi-class.ai/'>Zhi Class</a> of <a href='https://english.pku.edu.cn/'>Peking University (PKU)</a>, and I am also doing a research internship at <a href='https://www.icst.pku.edu.cn/index.htm'>Wangxuan Institute of Computer Technology, Peking University</a>, advised by Prof.<a href='http://www.csyangliu.com/'>Yang Liu</a>.

My research tenet is <em>Shut up and Calculate</em>.  My life tenet is <em>Be More Objective and Less Prejudiced</em>.

My research interest inlucdes <strong>Computer Vision</strong> and <strong>Multimodal Learning</strong>, and especially focuses on <strong>Generative Model</strong> and <strong>3D Vision</strong>. If you have interesting ideas or questions, feel free to contact me! ğŸ“§

<!-- I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=KK2hp8kAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span><<strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=KK2hp8kAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
- *2025.02*: &nbsp;ğŸ‰ğŸ‰ HCoG is accepted by CVPR 2025!
- *2024.02*: &nbsp;ğŸ‰ğŸ‰ Diff-BGM is accepted by CVPR 2024!

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/Diff-BGM.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Diff-BGM: A Diffusion Model for Video Background Music Generation](https://arxiv.org/pdf/2405.11913)

Sizhe Li, **Yiming Qin**, Minghang Zheng, Xin Jin, Yang Liu

[**\[ArXiv\]**](https://arxiv.org/abs/2405.11913) &nbsp;
[**\[PDF\]**](https://arxiv.org/pdf/2405.11913) &nbsp;
[**\[code\]**](https://github.com/sizhelee/Diff-BGM)
<!-- [**\[Project\]**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- <strong>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024</strong>
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.